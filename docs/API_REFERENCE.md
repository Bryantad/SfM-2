# SFM-2 API Reference

## FastAPI Endpoints

### Health Check

```http
GET /health
```

**Response:**

```json
{
  "status": "healthy",
  "model_status": {
    "sfm2": "available",
    "gpt2_lora": "available",
    "openai": "configured"
  },
  "timestamp": "2025-06-09T12:00:00Z"
}
```

### Code Generation

```http
POST /generate
```

**Request Body:**

```json
{
  "prompt": "def fibonacci(n):",
  "max_length": 100,
  "temperature": 0.7,
  "top_p": 0.9,
  "language": "python"
}
```

**Response:**

```json
{
  "generated_code": "def fibonacci(n):\n    if n <= 1:\n        return n\n    return fibonacci(n-1) + fibonacci(n-2)",
  "model_used": "sfm2",
  "confidence": 0.92,
  "processing_time": 0.15
}
```

### Batch Generation

```http
POST /generate/batch
```

**Request Body:**

```json
{
  "prompts": ["def quicksort(arr):", "class Node:", "import pandas as pd"],
  "max_length": 50,
  "language": "python"
}
```

## Python SDK

### Installation

```bash
pip install sfm2
```

### Basic Usage

```python
from sfm2 import SFM2Client

# Initialize client
client = SFM2Client(api_url="http://localhost:8000")

# Generate code
result = client.generate(
    prompt="def binary_search(arr, target):",
    max_length=100,
    language="python"
)

print(result.generated_code)
```

### Advanced Configuration

```python
from sfm2 import SFM2Client, GenerationConfig

client = SFM2Client(
    api_url="http://localhost:8000",
    api_key="your_api_key",  # If authentication is enabled
    timeout=30
)

config = GenerationConfig(
    temperature=0.8,
    top_p=0.9,
    top_k=50,
    repetition_penalty=1.1,
    max_length=200
)

result = client.generate(
    prompt="class BinaryTree:",
    config=config,
    language="python"
)
```

### Streaming Generation

```python
# For long code generations
for chunk in client.generate_stream(
    prompt="def complex_algorithm():",
    max_length=500
):
    print(chunk.text, end='')
```

### Batch Processing

```python
prompts = [
    "def sort_list(lst):",
    "class Queue:",
    "import numpy as np"
]

results = client.generate_batch(prompts, max_length=50)
for i, result in enumerate(results):
    print(f"Prompt {i+1}: {result.generated_code}")
```

## Model Manager API

### Direct Model Access

```python
from sfm2.core import ModelManager

manager = ModelManager()

# Check model health
health = manager.check_health()
print(f"SFM-2 Status: {health['sfm2']}")

# Generate with specific model
result = manager.generate_with_sfm2(
    prompt="def calculate_mean(numbers):",
    max_length=100
)
```

### Fallback Chain

```python
# The ModelManager automatically handles fallbacks:
# SFM-2 -> GPT-2 LoRA -> OpenAI GPT-3.5/4

result = manager.generate(
    prompt="def advanced_function():",
    max_length=150,
    use_fallback=True
)

print(f"Generated by: {result.model_used}")
```

## Configuration

### Environment Variables

```bash
# Required for OpenAI fallback
export OPENAI_API_KEY="your_openai_api_key"

# Optional configurations
export SFM2_MODEL_PATH="/path/to/sfm2/model"
export SFM2_API_PORT="8000"
export SFM2_LOG_LEVEL="INFO"
```

### Configuration File

```json
{
  "api": {
    "host": "0.0.0.0",
    "port": 8000,
    "workers": 4
  },
  "models": {
    "sfm2": {
      "path": "/path/to/sfm2/model",
      "device": "cuda",
      "max_memory": "8GB"
    },
    "gpt2_lora": {
      "base_model": "gpt2-medium",
      "lora_path": "/path/to/lora/weights"
    }
  },
  "generation": {
    "default_max_length": 100,
    "default_temperature": 0.7,
    "timeout": 30
  }
}
```

## Error Handling

### Common Error Responses

```json
{
  "error": "model_unavailable",
  "message": "SFM-2 model is currently unavailable",
  "fallback_used": "gpt2_lora",
  "suggestion": "Check model health endpoint"
}
```

### Python SDK Error Handling

```python
from sfm2 import SFM2Client, SFM2Error, ModelUnavailableError

client = SFM2Client(api_url="http://localhost:8000")

try:
    result = client.generate("def example():")
except ModelUnavailableError as e:
    print(f"Model error: {e.message}")
    print(f"Fallback used: {e.fallback_model}")
except SFM2Error as e:
    print(f"API error: {e}")
```

## Authentication & Rate Limiting

### API Key Authentication

```python
client = SFM2Client(
    api_url="http://localhost:8000",
    api_key="your_api_key"
)
```

### Rate Limiting

```http
HTTP/1.1 429 Too Many Requests
X-RateLimit-Limit: 100
X-RateLimit-Remaining: 0
X-RateLimit-Reset: 1623456789

{
  "error": "rate_limit_exceeded",
  "message": "Rate limit exceeded. Try again in 60 seconds"
}
```

## Performance Optimization

### Batch Processing

```python
# More efficient for multiple requests
prompts = ["def func1():", "def func2():", "def func3():"]
results = client.generate_batch(prompts)
```

### Caching

```python
from sfm2 import SFM2Client

client = SFM2Client(
    api_url="http://localhost:8000",
    enable_cache=True,
    cache_ttl=3600  # 1 hour
)
```

### Connection Pooling

```python
client = SFM2Client(
    api_url="http://localhost:8000",
    max_connections=10,
    keep_alive=True
)
```

## Monitoring & Metrics

### Health Monitoring

```python
health = client.health_check()
if health['status'] != 'healthy':
    print("API is experiencing issues")
```

### Usage Statistics

```http
GET /stats

{
  "total_requests": 15420,
  "successful_requests": 15381,
  "average_response_time": 0.23,
  "model_usage": {
    "sfm2": 14200,
    "gpt2_lora": 800,
    "openai": 381
  }
}
```

## Integration Examples

### VS Code Extension

```javascript
// VS Code extension integration
const sfm2 = require("sfm2-client");

const client = new sfm2.SFM2Client({
  apiUrl: "http://localhost:8000",
});

async function provideCodeCompletion(document, position) {
  const prompt = document.getText(
    new vscode.Range(0, 0, position.line, position.character)
  );
  const result = await client.generate(prompt, { maxLength: 50 });
  return new vscode.CompletionItem(result.generatedCode);
}
```

### Jupyter Notebook

```python
# Jupyter magic command
%load_ext sfm2

# Use in cells
%%sfm2 --language python --max-length 100
def calculate_statistics(data):
    # SFM-2 will complete this function
```

### CLI Tool

```bash
# Command line interface
sfm2 generate "def merge_sort(arr):" --max-length 200 --language python
sfm2 complete --file my_code.py --line 42
sfm2 explain --code "def mysterious_function(x, y): return x**2 + y**2"
```

For more examples and tutorials, see the [examples/](../examples/) directory.
